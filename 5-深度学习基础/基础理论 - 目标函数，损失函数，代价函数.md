# 目标函数，损失函数，代价函数

tags: 机器学习

---

[TOC]

## 1. 经验风险与结构风险

- 经验风险指的是模型对数据的拟合程度，拟合程度越高，经验风险越小。（其实对应的就是代价函数）
- 结构风险指的是对模型复杂度的评估，模型越复杂，结构风险越大。（其实对应的就是目标函数）

只考虑将经验风险最小化，会出现过拟合现象。

## 2. 损失函数，代价函数，目标函数

其实在很多论文和博客中都用的很随意，其实三者之间是有着细微的区别的：

- 损失函数（Loss Function）：一般针对单个样本的描述。其用来衡量模型预测值与真实值不一致的程度，是一个非负实值函数，通常使用 $L(Y, f(x))$ 表示。 损失函数越小，模型的鲁棒性就越好。

- 代价函数（Cost Function）：一般是针对总体。我们需要通过训练代价函数来获得最优参数，最常见的如平方差代价函数：
  $$
  J(\theta) = \frac{1}{m}\sum_{i=1}^m(h(x^{(i)})-y^{(i)})^2
  $$

- 目标函数（Object Function）：等价于 **代价函数 + 正则化项**， 其往往也是我们模型中要优化求解的函数 -- 目标函数。

## 3. 常用的损失函数

### 1 . 0-1 损失函数

$$
L(Y, f(x)) =
\begin{cases}
1,& Y\ne f(x)\\
0,& Y = f(x)
\end{cases}
$$

相等为 0 ， 不相等为1。一般的在实际使用中，相等的条件过于严格，可适当放宽条件：

$$
L(Y, f(x)) =
\begin{cases}
1,& |Y-f(x)|\geqslant T\\
0,& |Y-f(x)|< T
\end{cases}
$$

### 2. **绝对值损失函数**
$$
L(Y, f(x)) = |Y-f(x)|​
$$

### 3. **平方损失函数**

$$
L(Y|f(x)) = \sum_N {(Y-f(x))}^2
$$

### 4. **对数损失函数**

$$
L(Y, P(Y|X)) = -\log{P(Y|X)}
$$

常见的逻辑回归使用的就是对数损失函数。**逻辑回归它假设样本服从伯努利分布（0-1分布），进而求得满足该分布的似然函数，接着取对数求极值等**。

### 5. **指数损失函数**
指数损失函数的标准形式为：
$$
L(Y|f(x)) = \exp(-Yf(x))
$$
例如**AdaBoost就是以指数损失函数为损失函数。**

### 6. **Hinge损失函数**
$$
L(y) = \max{(0, 1-ty)}
$$

其中 $y$ 是预测值，范围为 $(-1,1)$ ，$t$ 为目标值，其为$-1$ 或 $1$。

在**线性支持向量机**中，最优化问题可等价于
$$
\underset{w,b}{\min}\sum_{i=1}^N (1-y_i(wx_i+b))+\lambda\Vert w\Vert ^2
$$
上式相似于下式
$$
\frac{1}{m}\sum_{i=1}^{N}l(wx_i+by_i) + \Vert w\Vert ^2
$$
其中$l(wx_i+by_i)$是Hinge损失函数，$\Vert w\Vert ^2$可看做为正则化项。

## 4. 常用的代价函数

**二次代价函数适合输出神经元是线性的情况，交叉熵代价函数适合输出神经元是S型函数的情况。**

### 1. 二次代价函数

$$
J = \frac{1}{2n}\sum_x\Vert y(x)-a^L(x)\Vert^2 \\
单样本：\frac{\partial J}{\partial w}=(a-y)\sigma'(z)x \\
单样本：\frac{\partial J}{\partial b}=(a-y)\sigma'(z)
$$

### 2. 交叉熵代价函数

$$
J = -\frac{1}{n}\sum_x[y\ln a + (1-y)\ln{(1-a)}] \\
\frac{\partial J}{\partial w_j}=\frac{1}{n}\sum_{x}x_j(\sigma{(z)}-y)\;，\\
\frac{\partial J}{\partial b}=\frac{1}{n}\sum_{x}(\sigma{(z)}-y)
$$

- 它是⾮负的， J > 0。可以看出：式子中的求和中的所有独⽴的项都是负数的，因为对数函数的定义域是 (0，1)，并且求和前⾯有⼀个负号，所以结果是非负。
- 如果对于所有的训练输⼊ x，神经元实际的输出接近⽬标值，那么交叉熵将接近 0。

### 3. 对数似然函数代价函数

交叉熵一般与 sigmoid 结合，而对数似然代价函数一般与 softmax 结合。 对数似然代价函数在二分类时可以化简为交叉熵代价函数的形式。



## QA

### 1. Sigmoid 为何与交叉熵搭配二不用二次方代价函数

如果使用二次方代价函数，根据权值$w$ 和 $b$ 的偏导：
$$
\frac{\partial J}{\partial w}=(a-y)\sigma'(z)x, \\
\frac{\partial J}{\partial b}=(a-y)\sigma'(z)
$$
考虑到 sigmoid 函数倒数在输出接近 0 和 1 时非常小， 会导致一些样本在刚开始训练时学习的非常慢。

### 2. sigmoid 为何要与交叉熵搭配

交叉熵函数权值$w$和偏置$b$的梯度推导为：
$$
\frac{\partial J}{\partial w_j}=\frac{1}{n}\sum_{x}x_j(\sigma{(z)}-y)\;，
\frac{\partial J}{\partial b}=\frac{1}{n}\sum_{x}(\sigma{(z)}-y)
$$
由以上公式可知，权重学习的速度受到$\sigma{(z)}-y$影响，更大的误差，就有更快的学习速度，避免了二次代价函数方程中因$\sigma'{(z)}$导致的学习缓慢的情况。

### 1. Logistic 回归为何要使用对数损失函数？

逻辑回归它假设样本服从**伯努利分布（0-1分布）**，进而求得满足该分布的似然函数，接着取对数求极值等。整个过程如下：

- Logistic 回归模型为：
  $$
  P(y=1|x;\theta)=\frac{1}{1+e^{-\theta^{T}x}}
  $$

- Logistic 回归的概率分布为伯努利分布，其概率函数为：
  $$
  P(X=n)=
  \begin{cases}
  1-p, n=0\\
   p,n=1
  \end{cases}
  $$

- 其似然函数为：
  $$
  L(\theta)=\prod_{i=1}^{m}
  P(y=1|x_i)^{y_i}P(y=0|x_i)^{1-y_i}
  $$

- 对应的对数似然函数为：（就是对上面的似然函数求对数）
  $$
  \ln L(\theta)=\sum_{i=1}^{m}[y_i\ln{P(y=1|x_i)}+(1-y_i)\ln{P(y=0|x_i)}]\\
    =\sum_{i=1}^m[y_i\ln{P(y=1|x_i)}+(1-y_i)\ln(1-P(y=1|x_i))]
  $$




将对数似然函数与上文提到的对数损失函数对比，发现，二者的本质是相同的，所以Logistic 直接采用对数损失函数。

### 4.为什么交叉熵损失相比均方误差损失能提高以 sigmoid 和 softmax 作为激活函数的层的性能？

简单来说，就是使用均方误差（MSE）作为损失函数时，会导致大部分情况下**梯度偏小**，其结果就是权重的更新很慢，且容易造成“梯度消失”现象。而交叉熵损失克服了这个缺点，当误差大的时候，权重更新就快，当误差小的时候，权重的更新才慢。

推导过程： https://blog.csdn.net/guoyunfei20/article/details/78247263

一、均方误差的权值更新过程（举例说明）

代价函数经常用方差代价函数（即采用均方误差MSE），比如对于一个神经元（单输入单输出，sigmoid函数）,定义其代价函数为：


其中y是我们期望的输出，a为神经元的实际输出【 a=σ(z), where z=wx+b 】。在训练神经网络过程中，我们通过梯度下降算法来更新w和b，因此需要计算代价函数对w和b的导数：


然后更新w、b：




因为sigmoid函数的性质，导致σ′(z)在z取大部分值时会很小（如下图标出来的两端，几近于平坦），这样会使得w和b更新非常慢（因为η * a * σ′(z)这一项接近于0）。


二、交叉熵代价函数（cross-entropy cost function）

为了克服MSE的这个缺点，引入了交叉熵代价函数：


其中：y为期望的输出，a为神经元实际输出【a=σ(z), where z=∑Wj*Xj+b】。我们同样看看它的导数：



可以看到，导数中没有σ′(z)这一项，权重的更新是受σ(z)−y这一项影响，即受误差的影响。所以当误差大的时候，权重更新就快，当误差小的时候，权重的更新就慢。这是一个很好的性质。

三、总结

    当用sigmoid函数作为神经元的激活函数时，最好使用交叉熵代价函数来替代方差代价函数，以避免训练过程太慢。
    不过，为什么是交叉熵函数？导数中不带σ′(z)项的函数有无数种，怎么就想到用交叉熵函数？这自然是有来头的，更深入的讨论就不写了。
    另外，交叉熵函数的形式是−[ylna+(1−y)ln(1−a)]，而不是 −[alny+(1−a)ln(1−y)]，为什么？因为当期望输出的y=0时，lny没有意义；当期望y=1时，ln(1-y)没有意义。而因为a是sigmoid函数的实际输出，永远不会等于0或1，只会无限接近于0或者1，因此不存在这个问题。
————————————————
版权声明：本文为CSDN博主「guoyunfei20」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。
原文链接：https://blog.csdn.net/guoyunfei20/java/article/details/78247263

### 5.  损失函数有哪些？ 怎么用？

- 平方损失 -- 预测问题
- 交叉熵 -- 分类问题
- Hinge 损失 -- SVM
- CART 回归树的残差损失



## Reference

[1] DeepLearning-500-questions

